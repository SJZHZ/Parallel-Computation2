# 并行计算 II 2023 春季第二次作业：<br> MPI 优化 Attention 算法
**1900017702 朱越**
## 0. 概要
本作业针对Attention算法使用MPI进行优化，

**TODO**

## 1. Attention算法
$$
Attention(\bf{Q},\bf{K},\bf{V}) = softmax(\frac{\bf{Q}\bf{K}^T} {\sqrt{d_k}}) \bf{V}
$$

## 2. 串行计算
```cpp
Matrix *kt = transpose(k);
Matrix *qk = matmul(q, kt);
Matrix *qk_s = scale(qk, 1.0 / sqrt(k->col));
Matrix *qk_s_s = softmax(qk_s);
Matrix *qkv = matmul(qk_s_s, v);
```

## 3. 并行计算
1. 矩阵乘法  
    * 公式
        $$
        \left(
        \begin{matrix}
        a_{ij}\\
        \end{matrix}
        \right)_{m \times n}
        \left(
        \begin{matrix}
        b_{ij}
        \end{matrix}
        \right)_{n \times p}
        =
        \left(
        \begin{matrix}
        \sum_{k = 1}^{n}{a_{ik}b_{kj}}\\
        \end{matrix}
        \right)_{m \times p}
        $$
    * 2*2分块
        $$
        \left(
        \begin{matrix}
        A_{11} & A_{12} \\
        A_{21} & A_{22}
        \end{matrix}
        \right)
        \left(
        \begin{matrix}
        B_{11} & B_{12} \\
        B_{21} & B_{22}
        \end{matrix}
        \right)
        =
        \left(
        \begin{matrix}
        A_{11}B_{11}+A_{12}B_{21} & A_{11}B_{12}+A_{12}B_{22} \\
        A_{21}B_{11}+A_{22}B_{21} & A_{21}B_{12}+A_{22}B_{22}
        \end{matrix}
        \right)
        $$
    * 时间复杂度  
        由分块得递推公式： $T(n) = 8 * T(\frac{n}{2}) + \Theta(n^2)$  
        由主定理得，时间复杂度：$O(n^3)$。

        （补充：存在一种Strassen算法可以把子矩阵的乘法降低到7次，此时时间复杂度可以降到$O(n^{log_2 7})$）
2. 分块乘法  
    > 分块乘法还可以扩展到任意的矩阵划分方式，只要左矩阵的按列划分和右矩阵的按行划分方式相等即可。在分块乘法中，观察各结果块的计算，发现彼此之间没有任何依赖，这给并行计算带来了可能性。接下来以最基础的两个形式分析可并行性：  
    * 空间划分：按左矩阵行或右矩阵列划分，分别计算各个空间
        $$
        \left(
        \begin{matrix}
        A_{1} \\
        A_{2}
        \end{matrix}
        \right)
        \left(
        \begin{matrix}
        B_{1} & B_{2}
        \end{matrix}
        \right)
        =
        \left(
        \begin{matrix}
        A_{1}B_{1} & A_{1}B_{2}\\
        A_{2}B_{1} & A_{2}B_{2}
        \end{matrix}
        \right)
        $$
    * 加数划分：按左矩阵列和右矩阵行划分，分别计算各个加数
        $$
            \left(
            \begin{matrix}
            A_{1} & A_{2} \\
            \end{matrix}
            \right)
            \left(
            \begin{matrix}
            B_{1}\\
            B_{2}
            \end{matrix}
            \right)
            =
            \left(
            \begin{matrix}
            A_{1}B_{1}+A_{2}B_{2}\\
            \end{matrix}
            \right)
        $$
3. 算子耦合
    > 对单个矩阵乘法而言，理论上可以使用任意的矩阵划分方式进行并行化。为了保证结果一致性，需要各控制流在并行计算后作结果同步：分别计算两块空间后，各个控制流归并；分别计算两个加数后，各个控制流聚合。总体通信量和负载量相同，效果区别不大。
    > 
    > 对矩阵算子的流水线而言，情况有所不同。由于前后结果是互相依赖的，最保守的方法是每个算子都保证结果一致性。然而，有一些情况下我们无需保证中间过程的结果一致性——前一个算子的并行划分输出正好满足后一个算子的并行划分输入，就能节省一次同步，满足“**通信极小**”的目标。由此，导出两点推论：  
        1. 如果后一个算子是按行/列并行划分任务的，则前一个算子尽可能选择按对应行/列并行输出结果的；反之亦然。
        2. 前一个算子尽量不选择加数划分，因为这种划分方式没有缩小后续问题规模，为了保证后续算子总任务量不变必然要进行同步规约。
    * Attention算法运用上述结论：
        1. softmax函数是按行划分，按行输出的，要求前算子按行输出，后算子按行输入。因此，第一步和最后一步矩阵乘法都应该是按行划分的。
        2. softmax函数是非线性的，如果选择加数划分，softmax函数不可以在两个加数上分别计算并聚合。因此不使用加数划分方式。
    * 因此得出本文的并行策略：
        $$
        Attention(\bf{Q_{row}},\bf{K},\bf{V}) = softmax(\frac{\bf{Q_{row}}\bf{K}^T} {\sqrt{d_k}}) \bf{V}
        $$
4. （补充：形式化定义）
    > 前述的“空间划分”和“加数划分”是我口头的称呼，随后我感觉到对于这种规律应该存在某种形式化的定义，因此我找到了在分布式机器学习训练系统中参考信息：
    1. 数据并行：SIMD，要求数据具有一定性质
        1. 数据内并行：数据可以划分为多个维度，各维度之间的计算图独立
        2. 数据间并行：多个批次样本独立计算，结果可聚合（或近似聚合）
    2. 算子并行：MISD，要求算子具有一定性质
        1. 算子内并行：算子可以划分为多个分量，各分量之间的计算图独立
        2. 算子间并行：多个顺序依赖算子可流水线化（同时把数据也按批次划分）
    * 在attention算法中，虽然是大规模矩阵运算，但由于它特殊的按行独立性质，本文对其按行划分作数据内并行。
    ### References
    * [算子级并行和流水线并行——MindSpore](https://www.mindspore.cn/tutorials/experts/zh-CN/r2.0.0-alpha/parallel/pipeline_parallel.html)
    * [数据并行和模型并行——OPEN MLSYS](https://openmlsys.github.io/chapter_distributed_training/methods.html#id5)
    * [Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning](https://arxiv.org/abs/2201.12023)

5. 节点与核心，进程与线程
    * 节点与核心
        > 在集群上限制使用总核心数一定时，任务是集中在少量节点的更多核心上更快，还是更多节点的少数核心上更快？对于attention问题的并行计算而言，在按照前一节所述方式进行任务划分后，计时部分内不涉及彼此之间的数据传输，因此在理论上并无区别。
        > 
        > 但在实验中，单节点16核的平均表现不如四节点4核的平均表现，并且表现出性能抖动。这可能是因为单个机器的频率存在上限，多个核心并行工作时达到峰值，计算能力受限，而在多个节点上则快速且稳定。
    * 进程与线程
        > 同理，在计时部分中各控制流间不存在数据传输，理论上并无区别。
        > 但在实验中，由于我没有花精力针对多线程编程作优化，仅在for循环部分作了并行化，这样每次循环之前都要初始化并行区，产生了额外的代价，肯定是不如用进程作并行的。
    * 结论：使用四节点4核心的配置，启动16个进程作并行，每个进程都是单线程工作的。

6. 编译选项
    > 编译器可以帮我们优化一些公共子表达式等情况。然而编译优化和并行计算部分的耦合比较复杂，在深度优化后往往不是简单的乘性关系或加性关系。另一方面，最终结果必然包含编译优化选项，因此，为了取得最终效果最好的组合，任何深度优化都应该在开启编译优化的情况下进行。因此，只讨论最初的两个编译优化情况。以下是在方案和并行方案下观察-Ofast选项的运行结果，可以看到，随着并行优化的进行，编译优化效果的绝对值减少，但相对比例提升了。
    ```txt
    basic
    Matrix size: 2048 x 1024
    Ans: 1048568.4615699096
    Your answer: 1048568.4615698808
    Correct! Time: 73.7376849651
    basic -Ofast
    Matrix size: 2048 x 1024
    Ans: 1048568.4615699096
    Your answer: 1048568.4615698811
    Correct! Time: 21.7690162659
    final without Opt
    Matrix size: 2048 x 1024
    Ans: 1048568.4615699096
    Your answer: 1048568.4615698837
    Correct! Time: 4.8341712952
    final
    Matrix size: 2048 x 1024
    Ans: 1048568.4615699096
    Your answer: 1048568.4615698837
    Correct! Time: 0.7029755116
    ```

7. 缓存优化
    > 在Attention算法中，主要计算代价集中在矩阵乘法上，时间复杂度$O(n^3)$，其余部分都是$O(n^2)$的，在计算规模较大时所占比例很小。因此，接下来的优化仅针对矩阵乘法。
    * 存储方式
        > 对于二维矩阵的访存，按行遍历空间局部性好，而按列遍历空间局部性差。而矩阵乘法又需要计算一行乘以一列。因此，可以把右矩阵预先作转置，这样就变成两个矩阵都按行访问，对缓存线友好。另一方面，题目允许改变矩阵的存储方式，因此提前转置可以不计入算法运行时间中。
    * 遍历顺序
        > 在已经改变过存储方式后，对于两个乘子矩阵而言，都是按相同行下标k连续访问的，因此最内层循环应该遍历k，以最大限度利用空间局部性。
        > 
        > 现讨论外两层循环的i和j。在两个乘子部分，i和j是地位相等的，只有在结果部分，i对应行而j对应列。直观上来说，现遍历i再遍历j会对结果矩阵C[i][j]有空间局部性，但在实际尝试中发现似乎不是这样。
    * 循环展开


7. surprise!
    * 负载均衡假设？
        > 在尝试调配负载的过程中，我发现这个计时模块有点疏漏：可以利用这个计时模块的非同步性把时间偷了。
        > 
        > 计时方式假设了编程者是忠实作负载均衡的，各个进程用时基本相等，因此只计算了主进程在attention模块的时间。然而，经过有意的设计，主进程可以不安排负载，这样反馈时间就约等于零，即使其他进程仍处于工作之中。由于reduce部分作了集合通信而包含隐式同步，还能保证结果的正确性。

    * 结束标志
        > 为了把计时部分变严格，应该对运行时间变量也作一次MAX的reduce，或者在计时部分的最后加上显式的栅栏同步。这两种方法分别对应两种理解方式：并行计算的是按最后一个进程计算完成为标志，还是按所有进程都知道计算完成为标志？
        > 
        > 假设每个进程的运行时长是一个随机变量，那么理论上前者比修改之前期望有所增加，实际测得并不显著，即随机变量方差并不大。而后者比前者多一次Allreduce所耗时间，实际测得时间明显增加（在高度优化的情况下），即多节点间通信成本更大。
## 4. 最终策略
在前一节中
## 5. 结果复现
