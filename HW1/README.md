# 并行计算 II 2023 春季第一次作业：<br> OpenMP 优化 Bellman-Ford 算法

## 1. Bellman-Ford 算法
    单源最短路径，以0点为起点，通过邻接矩阵更新距离向量  
    输入：邻接矩阵mat  
    输出：距离向量d  
    算法：  
        初始化：d[0]=0  
        状态转移：d[x] = min(d[x], d[y]+w[y][x])  
        终止条件：在某次迭代后没有发生更新，或已迭代了n-1轮。  
            此时需要多迭代一轮，判定负权。

## 2. 串行计算
    见serial.cpp

## 3. 并行计算
* 基本分析
    > 状态转移：d[x] = min(d[x], d[y]+w[y][x])  
    > 基于上述状态转移过程，各状态可以独立计算。但必须注意：  
    > 1. 最外层循环即迭代轮数不可作并行，因为这是顺序依赖的，而两层内层循环则可以**选择性地作并行**。如何设置并行区？可以在每轮迭代时开辟并行区，也可以使用持久化的并行区。
    > 2. 算法的一个终止条件是基于最短路径长度不超过n，这要求我们必须保证遍历过路径长为n的所有路径，对变量之间限定了一定的依赖关系。如果是完全独立地计算，可能某一点在计算了n步后其他点都还未开始，这将导致不能给出正确的结果。因此，在每轮迭代后需要作**栅栏同步**，此外，对has_change的共享也需要同步。
    > 3. 对串行计算而言，每轮迭代更新的内层两重循环——途径点和终点，遍历顺序并无区别。而对并行计算而言，**遍历顺序在缓存意义上有区别**。

### 状态转移：d[x] = min(d[x], d[y]+w[y][x])
* 终点优先
    > 在一轮迭代中，每个线程保持终点不变，只对遍历的途径点作并行，即并行遍历y。  
    > 这样的好处是每个线程独立维护自己的可变变量d[x]，但读d[y]时可能也会发生读-写冲突。

* 途径点优先
    > 在一轮迭代中，每个线程保持途径点不变，只对遍历的终点作并行，即并行遍历x。  
    > 这样的好处是每个线程维护同一个只读变量d[y]。问题在于，线程之间共享可变变量d[x]，可能会产生写-写冲突。

* 完全并行 
    > 在一轮迭代中，同时对终点和途径点作并行。实际操作中，由于线程数远小于循环次数，即一层循环上不足以充分展开，故不必考虑此种情况。

## 4. 因素分析
* 流程
    ```zsh
    # 记得在编译时添加选项 -fopenmp
    make
    sbatch run.slurm
    ```
* 串行计算  
    > 见serial.cpp。平均时间约0.24s
* 核心数和线程数
    1. 单核  
        > 平均时间约0.3s，比串行计算还慢。因为在一个核心上多线程计算实际上还是串行执行的，还需要额外调度的时间。
    2. 多核  
        ```zsh
        # 登录节点
        sinfo --Node --long
        scontrol show node
        # 计算节点
        lscpu
        ```
        > 在登录节点使用sinfo命令和scontrol命令可以查看各节点信息。  
        > 在计算节点使用slurm脚本获取该节点详细信息  
        > 
        > 线程数最好与硬件核心数匹配，这样能最大限度地并行化，考虑包括：  
        > 1. 是否支持超线程？若是，则一个核心可以运行多个线程以增加并行度（但达不到多核的并行度）。  
        > 2. 一个节点的核心是单路还是多路？如果是多路，需要权衡访存一致性和硬件资源的优劣：各路之间不共享缓存，但共享内存，对同一片数据并行操作会增加延迟。而增加路数可以使计算资源加倍。
        > 3. 虽然每个节点的CPU数基本都是24核，但在提交批处理脚本时不允许申请这么多个核心。理论上说对双路12核节点，极限情况是申请12核，但可能由于还要留一部分给系统其他事务而发生调度，所以在接近12核时性能很不稳定。

        结论：经过实验，在核心数和线程数均为12时，速度最快，但偶尔较慢；在核心数和线程数为8时，速度稳定。猜测：可能是该节点上的部分核心较忙，此时要么等待任务调度，要么分配到两个不同插槽的核心，都会导致速度降低？
* 临时或持久
    > 最简单的做法是每轮迭代都开辟一个并行区，并行区内划分循环，但每轮都需要初始化并行区，这可能引入额外的调度开销。  
    > 或许可以尝试使用持久化的并行区，在不同轮次间作一次栅栏同步即可。  
    > __TODO__

* 循环优先顺序
    > 在一轮迭代中：  
    > 一方面肯定是尽量把并行循环放在外层，而把重复计算的部分放在内存  
    > 另一方面，外层所遍历的变量可以选择是途径点还是终点。根据前一节中的讨论，二者各有优势：终点优先可以独立维护dist[v]的改变；途径点优先可以保持。
    > 结论：途径点优先的策略速度更快

* 缓存
    > 鉴于一个线程经常访问同一个变量，因此可以对重复访问的部分作线程缓存。虽然手动缓存也需要基础开销，但在访问次数较多时还是能够加速。  
    > 可能复用的变量包括：has_change, dist[v], dist[u]，依据不同循环方式确定。  
    > 对于dist[u]的缓存几乎没有效果，可能是编译器已经推测出dist[u]的不变性，已经作了缓存优化
* 正确性检查
    > 将输出output.txt与串行结果output_std.txt进行比对  
    > 各算法结果均正确  
    > **TODO**
* 时长比较
    ```text

    ```
    > 以上是执行一次脚本所反馈的结果。  
    > 其中
    > 
## 最终方案
直观上看，上述几种因素大致是正交的，所以最自然的方案是在每种因素上选择最优方案，组合起来即可。